<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="3D Foundation Policy for Robotic Manipulation.">
  <meta name="keywords" content="FP3, 3D Foundation Policy, Robotic Manipulation, Robotics, Machine Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FP3: A 3D Foundation Policy for Robotic Manipulation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/thu_logo.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">FP3: A 3D Foundation Policy for Robotic Manipulation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a>Rujia Yang</a><sup>*1</sup>,</span>
            <span class="author-block">
              <a>Geng Chen</a><sup>*2,4</sup>,</span>
            <span class="author-block">
              <a>Chuan Wen</a><sup>‡1,2,3</sup>,
            </span>
            <span class="author-block">
              <a>Yang Gao</a><sup>‡1,2,3</sup>,
            </span>
            <!-- <span class="author-block">
              <a href="http://sofienbouaziz.com">Sofien Bouaziz</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.danbgoldman.com">Dan B Goldman</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="http://www.ricardomartinbrualla.com">Ricardo Martin-Brualla</a><sup>2</sup>
            </span> -->
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>IIIS, Tsinghua University,</span>
            <span class="author-block"><sup>2</sup>Shanghai AI Laboratory,</span>
            <span class="author-block"><sup>3</sup>Shanghai Qi Zhi Institute,</span>
            <span class="author-block"><sup>4</sup>UC San Diego</span>
            <span class="author-block"><sup>*</sup>Equal Contribution</span>
            <span class="author-block"><sup>‡</sup>Equal Advising</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2503.08950"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. (Coming Soon)-->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <div class="publication-video">
        <iframe src="./static/images/fp3_video.mp4"
                frameborder="0" allowfullscreen width="360" height="180"></iframe>
      </div>

    </div>
  </div>
  <div style="text-align: center;">
    <img src="./static/concept.jpg" width="80%" height="600px", alt="FP3 Concept">
  </div>
</section>


<section class="hero is-light is-small">
  <!-- <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div> -->
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Following its success in natural language processing and computer vision, foundation models that are pre-trained on large-scale multi-task datasets have also shown great potential in robotics. However, most existing robot foundation models rely solely on 2D image observations, ignoring 3D geometric information, which is essential for robots to perceive and reason about the 3D world. In this paper, we introduce FP3, a first large-scale 3D foundation policy model for robotic manipulation. FP3 builds on a scalable diffusion transformer architecture and is pre-trained on 60k trajectories with point cloud observations. With the model design and diverse pre-training data, FP3 can be efficiently fine-tuned for downstream tasks while exhibiting strong generalization capabilities. Experiments on real robots demonstrate that with only 80 demonstrations, FP3 is able to learn a new task with over 90% success rates in novel environments with unseen objects, significantly surpassing existing robot foundation models.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
      <!-- Visual Effects. -->
      <div class="columns is-centered has-text-centered">
        <div class="content">
          <h2 class="title is-3">Generalization</h2>
          <p>
            We conduct more comprehensive experiments on FP3's generalizability to different environments and robot setups using the Clean Table task.
          </p>
          <div class="select" style="display: block;">
              <select id="task-selection" style="width: 100%;">
                <option value="./static/videos/in_domain_converted.mp4">In Domain</option>
                <option value="./static/videos/background_converted.mp4">Unseen Background</option>
                <option value="./static/videos/distractor_converted.mp4">Unseen Distractor</option>
                <option value="./static/videos/object_converted.mp4">Unseen Object</option>
                <option value="./static/videos/light_converted.mp4">Unseen Light Condition</option>
                <option value="./static/videos/camera_converted.mp4">Unseen Camera View</option>
              </select>
          </div>
          <video id="generalization" autoplay controls muted loop playsinline height="100%">
              <source id="video-source" src="./static/videos/in_domain_converted.mp4" type="video/mp4">
          </video>
          <script>
              document.getElementById('task-selection').addEventListener('change', function() {
                  let videoPlayer = document.getElementById('generalization');
                  let videoSource = document.getElementById('video-source');
                  let selectedVideo = this.value;

                  videoSource.src = selectedVideo; // 修改 source 的 src
                  videoPlayer.load(); // 重新加载视频
                  videoPlayer.play(); // 播放新的视频
              });
          </script>
        </div>
      </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{yang2025fp33dfoundationpolicy,
      title={FP3: A 3D Foundation Policy for Robotic Manipulation}, 
      author={Rujia Yang and Geng Chen and Chuan Wen and Yang Gao},
      year={2025},
      eprint={2503.08950},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2503.08950}, 
}</code></pre>
  </div>
</section>

</body>
</html>
